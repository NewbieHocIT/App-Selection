import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps
import os
import mlflow
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

def load_mnist():
    X = np.load("data/mnist/X.npy")
    return X

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu n·ªïi ti·∫øng v√† ph·ªï bi·∫øn nh·∫•t trong c·ªông ƒë·ªìng h·ªçc m√°y, 
      ƒë·∫∑c bi·ªát l√† trong c√°c nghi√™n c·ª©u v·ªÅ nh·∫≠n di·ªán m·∫´u v√† ph√¢n lo·∫°i h√¨nh ·∫£nh.
  
      - B·ªô d·ªØ li·ªáu bao g·ªìm t·ªïng c·ªông **70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay** t·ª´ **0** ƒë·∫øn **9**, 
        m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28 x 28 pixel**.
      - Chia th√†nh:
        - **Training set**: 60.000 ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán.
        - **Test set**: 10.000 ·∫£nh ƒë·ªÉ ki·ªÉm tra.
      - M·ªói h√¨nh ·∫£nh l√† m·ªôt ch·ªØ s·ªë vi·∫øt tay, ƒë∆∞·ª£c chu·∫©n h√≥a v√† chuy·ªÉn th√†nh d·∫°ng grayscale (ƒëen tr·∫Øng).
  
      D·ªØ li·ªáu n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh nh·∫≠n di·ªán ch·ªØ s·ªë.
      """)

    st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset")
    st.image("mnit.png", caption="M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset", use_container_width=True)

    st.subheader("·ª®ng d·ª•ng th·ª±c t·∫ø c·ªßa MNIST")
    st.write("""
      B·ªô d·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu ·ª©ng d·ª•ng nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay, ch·∫≥ng h·∫°n nh∆∞:
      - Nh·∫≠n di·ªán s·ªë tr√™n c√°c ho√° ƒë∆°n thanh to√°n, bi√™n lai c·ª≠a h√†ng.
      - X·ª≠ l√Ω ch·ªØ s·ªë tr√™n c√°c b∆∞u ki·ªán g·ª≠i qua b∆∞u ƒëi·ªán.
      - ·ª®ng d·ª•ng trong c√°c h·ªá th·ªëng nh·∫≠n di·ªán t√†i li·ªáu t·ª± ƒë·ªông.
    """)

    st.subheader("V√≠ d·ª• v·ªÅ c√°c m√¥ h√¨nh h·ªçc m√°y v·ªõi MNIST")
    st.write("""
      C√°c m√¥ h√¨nh h·ªçc m√°y ph·ªï bi·∫øn ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi b·ªô d·ªØ li·ªáu MNIST bao g·ªìm:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)




def split_data():
    st.title("üìå Chia d·ªØ li·ªáu (Unsupervised Learning)")

    # T·∫£i d·ªØ li·ªáu MNIST
    X = load_mnist()
    total_samples = X.shape[0]
    if "clustering_split_done" not in st.session_state:
        st.session_state.clustering_split_done = False


    # Kh·ªüi t·∫°o c√°c thu·ªôc t√≠nh trong session_state n·∫øu ch∆∞a t·ªìn t·∫°i
    if "test_size" not in st.session_state:
        st.session_state.test_size = 0.1  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
    if "train_size" not in st.session_state:
        st.session_state.train_size = 0
    if "total_samples" not in st.session_state:
        st.session_state.total_samples = total_samples

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ s·ª≠ d·ª•ng
    num_samples = st.slider(
        "Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ s·ª≠ d·ª•ng:", 
        min_value=1000, 
        max_value=total_samples, 
        value=10000
    )

    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test (n·∫øu c·∫ßn)
    test_size = st.slider(
        "Ch·ªçn t·ª∑ l·ªá test (ƒê·ªÉ ƒë√°nh gi√°)", 
        min_value=0.0, 
        max_value=0.5, 
        value=0.1, 
        step=0.1
    )

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u", key="split_data_confirm_button"):
        st.session_state.clustering_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")

        st.session_state.test_size = test_size
        st.session_state.train_size = num_samples * (1 - test_size)

        # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh mong mu·ªën
        X_selected = X[:num_samples]

        # Chia train/test (n·∫øu test_size > 0)
        if test_size > 0:
            X_train, X_test = train_test_split(X_selected, test_size=test_size, random_state=42)
            st.session_state["clustering_X_train"] = X_train
            st.session_state["clustering_X_test"] = X_test
            st.success(f"üîπ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia: Train ({len(X_train)}), Test ({len(X_test)})")
        else:
            # N·∫øu kh√¥ng chia test, s·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu
            st.session_state["clustering_X_train"] = X_selected
            st.session_state["clustering_X_test"] = np.array([])  # Kh√¥ng c√≥ t·∫≠p test
            st.success(f"üîπ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng: {len(X_selected)} ·∫£nh")

    if "X_train" in st.session_state:
        st.write("üìå D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng!")


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")


def train():
    mlflow_input()

    # Ki·ªÉm tra xem d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia ch∆∞a (s·ª≠ d·ª•ng key "clustering_X_train")
    if "clustering_X_train" not in st.session_state or "clustering_X_test" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # L·∫•y d·ªØ li·ªáu t·ª´ session_state
    X_train = st.session_state["clustering_X_train"]
    X_test = st.session_state["clustering_X_test"]

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0 if X_test.size > 0 else None

    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    model_choice = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh:", 
        ["K-means", "DBSCAN"], 
        key="clustering_model_choice_selectbox"  # Th√™m key duy nh·∫•t
    )

    if model_choice == "K-means":
        st.markdown("""
        - **K-means** l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm d·ªØ li·ªáu.
        - **Tham s·ªë c·∫ßn ch·ªçn:**  
            - **n_clusters**: S·ªë l∆∞·ª£ng c·ª•m.  
        """)
        n_clusters = st.slider(
            "n_clusters", 
            2, 20, 10, 
            key="clustering_n_clusters_slider"  # Th√™m key duy nh·∫•t
        )
        model = KMeans(n_clusters=n_clusters)

    elif model_choice == "DBSCAN":
        st.markdown("""
        - **DBSCAN** l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô.
        """)
        eps = st.slider(
            "eps (Kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa hai ƒëi·ªÉm ƒë·ªÉ coi l√† l√¢n c·∫≠n)", 
            0.01, 1.0, 0.5, 
            key="clustering_eps_slider"  # Th√™m key duy nh·∫•t
        )
        min_samples = st.slider(
            "min_samples (S·ªë l∆∞·ª£ng ƒëi·ªÉm t·ªëi thi·ªÉu trong m·ªôt l√¢n c·∫≠n)", 
            2, 20, 5, 
            key="clustering_min_samples_slider"  # Th√™m key duy nh·∫•t
        )
        model = DBSCAN(eps=eps, min_samples=min_samples)

    run_name = st.text_input(
        "üîπ Nh·∫≠p t√™n Run:", 
        "Default_Run", 
        key="clustering_run_name_input"  # Th√™m key duy nh·∫•t
    )
    st.session_state["run_name"] = run_name if run_name else "default_run"

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh", key="clustering_train_button"):  # Th√™m key duy nh·∫•t
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)  # Thanh ti·∫øn tr√¨nh
            status_text = st.empty()  # Hi·ªÉn th·ªã tr·∫°ng th√°i t·ª´ng b∆∞·ªõc

            # B∆∞·ªõc 1: Hu·∫•n luy·ªán m√¥ h√¨nh
            status_text.text("‚è≥ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh...")
            progress_bar.progress(30)

            model.fit(X_train)
            labels = model.labels_

            # B∆∞·ªõc 2: T√≠nh to√°n silhouette score
            status_text.text("üìä ƒêang t√≠nh to√°n silhouette score...")
            progress_bar.progress(60)

            if len(np.unique(labels)) > 1:
                silhouette_avg = silhouette_score(X_train, labels)
                st.success(f"üìä **Silhouette Score**: {silhouette_avg:.4f}")
                mlflow.log_metric("silhouette_score", silhouette_avg)
            else:
                st.warning("‚ö† Kh√¥ng th·ªÉ t√≠nh silhouette score v√¨ ch·ªâ c√≥ m·ªôt c·ª•m.")

            # B∆∞·ªõc 3: Logging v·ªõi MLflow
            status_text.text("üìù ƒêang ghi log v√†o MLflow...")
            progress_bar.progress(80)

            mlflow.log_param("model", model_choice)
            if model_choice == "K-means":
                mlflow.log_param("n_clusters", n_clusters)
            elif model_choice == "DBSCAN":
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)

            mlflow.sklearn.log_model(model, model_choice.lower())

            # B∆∞·ªõc 4: L∆∞u m√¥ h√¨nh v√†o session_state
            status_text.text("üíæ ƒêang l∆∞u m√¥ h√¨nh...")
            progress_bar.progress(90)

            if "clustering_models" not in st.session_state:
                st.session_state["clustering_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "DBSCAN":
                model_name += f"_eps{eps}_min_samples{min_samples}"
            elif model_choice == "K-means":
                model_name += f"_n_clusters{n_clusters}"

            existing_model = next((item for item in st.session_state["clustering_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["clustering_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")

            st.session_state["clustering_models"].append({"name": model_name, "model": model})
            st.write(f"üîπ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
            st.write(f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['clustering_models'])}")

            st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:")
            model_names = [model["name"] for model in st.session_state["clustering_models"]]
            st.write(", ".join(model_names))

            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **Train_{st.session_state['run_name']}**!")
            status_text.text("üíæ ƒê√£ l∆∞u")
            progress_bar.progress(100)

from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps

def du_doan():
    st.title("üî¢ D·ª± ƒëo√°n ph√¢n c·ª•m")

    # Ki·ªÉm tra xem ƒë√£ c√≥ m√¥ h√¨nh ch∆∞a
    if "clustering_models" not in st.session_state or not st.session_state["clustering_models"]:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return

    # Ch·ªçn m√¥ h√¨nh
    model_names = [model["name"] for model in st.session_state["clustering_models"]]
    selected_model_name = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán:", model_names)
    selected_model = next(model["model"] for model in st.session_state["clustering_models"] if model["name"] == selected_model_name)

    # Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p ·∫£nh
    input_option = st.radio("üñº Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["T·∫£i l√™n ·∫£nh", "V·∫Ω s·ªë"], 
                            horizontal=True,
                            key="input_option_radio"  # Th√™m key
                            )

    img_array = None  # L∆∞u ·∫£nh ƒë·∫ßu v√†o

    if input_option == "T·∫£i l√™n ·∫£nh":
        uploaded_file = st.file_uploader("üì§ T·∫£i l√™n ·∫£nh ch·ªØ s·ªë vi·∫øt tay (28x28 pixel)", 
                                         type=["png", "jpg", "jpeg"],key="file_uploader" )
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file).convert("L")
                image = ImageOps.invert(image)
                image = image.resize((28, 28))
                st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=False)

                img_array = np.array(image).reshape(1, -1) / 255.0

            except Exception as e:
                st.error(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}")

    elif input_option == "V·∫Ω s·ªë":
        st.write("‚úèÔ∏è V·∫Ω s·ªë b√™n d∆∞·ªõi (d√πng chu·ªôt ho·∫∑c c·∫£m ·ª©ng):")
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            width=280,
            height=280,
            drawing_mode="freedraw",
            key="canvas"
        )

        if canvas_result.image_data is not None:
            try:
                image = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
                image = image.resize((28, 28)).convert("L")
                image = ImageOps.invert(image)
                st.image(image, caption="·∫¢nh v·∫Ω ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω", use_column_width=False)

                img_array = np.array(image).reshape(1, -1) / 255.0

            except Exception as e:
                st.error(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh v·∫Ω tay: {str(e)}")

    # N√∫t d·ª± ƒëo√°n
    if img_array is not None:
        if st.button("üöÄ D·ª± ƒëo√°n",key="predict_button"):
            if isinstance(selected_model, DBSCAN):
                st.warning("‚ö†Ô∏è DBSCAN kh√¥ng h·ªó tr·ª£ d·ª± ƒëo√°n tr·ª±c ti·∫øp.")
                st.write("üî¢ Nh√£n c·ª•m t·ª´ qu√° tr√¨nh hu·∫•n luy·ªán:")
                st.write(selected_model.labels_)

                num_noise = np.sum(selected_model.labels_ == -1)
                st.write(f"üî¢ S·ªë l∆∞·ª£ng ƒëi·ªÉm nhi·ªÖu (noise): **{num_noise}**")

            elif isinstance(selected_model, KMeans):
                prediction = selected_model.predict(img_array)
                st.success(f"üî¢ D·ª± ƒëo√°n nh√£n c·ª•m: **{prediction[0]}**")
                st.write("üî¢ T√¢m c·ª•m (centroids):")
                st.write(selected_model.cluster_centers_)

            else:
                st.error("‚ö†Ô∏è M√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ trong ch·ª©c nƒÉng n√†y.")

            # Hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh
            st.write("üìã **Th√¥ng tin m√¥ h√¨nh:**")
            st.write(f"- T√™n m√¥ h√¨nh: **{selected_model_name}**")
            st.write(f"- Lo·∫°i m√¥ h√¨nh: **{type(selected_model).__name__}**")



def show_experiment_selector():
    st.title("üìä MLflow Experiments")

    experiment_name = "Clustering"
    
    # L·∫•y danh s√°ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # T·∫°o danh s√°ch run name v√† map v·ªõi run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Ch·ªçn run theo t√™n
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", list(run_dict.keys()),key="run_selector_selectbox" )
    selected_run_id = run_dict[selected_run_name]

    # L·∫•y th√¥ng tin c·ªßa run ƒë√£ ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")


def Clustering():
    st.title("üñäÔ∏è MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["üìò Data", "‚öôÔ∏è Hu·∫•n luy·ªán", "üî¢ D·ª± ƒëo√°n", "üî•Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clustering()